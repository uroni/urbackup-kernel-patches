--- linux-5.9.6/fs/io-wq.c.orig	2020-11-26 16:59:28.910906029 +0100
+++ linux-5.9.6/fs/io-wq.c	2020-11-26 17:05:02.022553497 +0100
@@ -119,6 +119,8 @@
 	refcount_t refs;
 	struct completion done;
 
+	unsigned int task_flags;
+
 	refcount_t use_refs;
 };
 
@@ -214,6 +216,7 @@
 
 	preempt_disable();
 	current->flags &= ~PF_IO_WORKER;
+	current->flags &= ~wqe->wq->task_flags;
 	if (worker->flags & IO_WORKER_F_RUNNING)
 		atomic_dec(&acct->nr_running);
 	if (!(worker->flags & IO_WORKER_F_BOUND))
@@ -312,6 +315,7 @@
 	allow_kernel_signal(SIGINT);
 
 	current->flags |= PF_IO_WORKER;
+	current->flags |= wqe->wq->task_flags;
 
 	worker->flags |= (IO_WORKER_F_UP | IO_WORKER_F_RUNNING);
 	worker->restore_files = current->files;
@@ -730,6 +734,8 @@
 {
 	struct io_wq *wq = data;
 	int node;
+	
+	current->flags |= wq->task_flags;
 
 	/* create fixed workers */
 	refcount_set(&wq->refs, 1);
@@ -1042,7 +1048,7 @@
 	return io_wq_cancel_cb(wq, io_wq_io_cb_cancel_data, (void *)cwork, false);
 }
 
-struct io_wq *io_wq_create(unsigned bounded, struct io_wq_data *data)
+struct io_wq *io_wq_create(unsigned bounded, struct io_wq_data *data, unsigned int task_flags)
 {
 	int ret = -ENOMEM, node;
 	struct io_wq *wq;
@@ -1063,6 +1069,8 @@
 	wq->free_work = data->free_work;
 	wq->do_work = data->do_work;
 
+	wq->task_flags = task_flags;
+
 	/* caller must already hold a reference to this */
 	wq->user = data->user;
 
--- linux-5.9.6/fs/io_uring.c.orig	2020-11-26 17:05:53.080339772 +0100
+++ linux-5.9.6/fs/io_uring.c	2020-11-26 17:11:52.420909848 +0100
@@ -7478,6 +7478,7 @@
 	struct io_ring_ctx *ctx_attach;
 	unsigned int concurrency;
 	int ret = 0;
+	unsigned int task_flags;
 
 	data.user = ctx->user;
 	data.free_work = io_free_work;
@@ -7487,7 +7488,13 @@
 		/* Do QD, or 4 * CPUS, whatever is smallest */
 		concurrency = min(ctx->sq_entries, 4 * num_online_cpus());
 
-		ctx->io_wq = io_wq_create(concurrency, &data);
+		task_flags = 0;
+		if(current->flags & PF_LOCAL_THROTTLE)
+			task_flags |= PF_LOCAL_THROTTLE;
+		if(current->flags & PF_MEMALLOC_NOIO)
+			task_flags |= PF_MEMALLOC_NOIO;
+
+		ctx->io_wq = io_wq_create(concurrency, &data, task_flags);
 		if (IS_ERR(ctx->io_wq)) {
 			ret = PTR_ERR(ctx->io_wq);
 			ctx->io_wq = NULL;
--- linux-5.9.6/fs/io-wq.h.orig	2020-11-26 17:15:21.376218023 +0100
+++ linux-5.9.6/fs/io-wq.h	2020-11-26 17:15:11.303865768 +0100
@@ -112,7 +112,7 @@
 	free_work_fn *free_work;
 };
 
-struct io_wq *io_wq_create(unsigned bounded, struct io_wq_data *data);
+struct io_wq *io_wq_create(unsigned bounded, struct io_wq_data *data, unsigned int task_flags);
 bool io_wq_get(struct io_wq *wq, struct io_wq_data *data);
 void io_wq_destroy(struct io_wq *wq);
 
